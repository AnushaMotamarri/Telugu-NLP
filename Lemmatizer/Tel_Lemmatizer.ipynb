{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "lines= pd.read_table('/home/anusha/pCloudDrive/thesis/translator/Word-Level-Eng-Mar-NMT/Telugu-Seq2Seq-stemmer/data/allsimplew5.txt'\n",
    ", names=['eng', 'tel'])\n",
    "linestest=pd.read_table('/home/anusha/pCloudDrive/thesis/translator/Word-Level-Eng-Mar-NMT/Telugu-Seq2Seq-stemmer/data/allsimpletest2.txt', names=['eng', 'tel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2603, 2), (233, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape,linestest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.eng=lines.eng.str.lower()\n",
    "lines.tel=lines.tel.str.lower()\n",
    "linestest.eng=linestest.eng.str.lower()#apply(lambda x: x.lower())\n",
    "linestest.tel=linestest.tel.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', str(x)))\n",
    "lines.tel=lines.tel.apply(lambda x: re.sub(\"'\", '', str(x)))\n",
    "linestest.eng=linestest.eng.apply(lambda x: re.sub(\"'\", '', str(x)))\n",
    "linestest.tel=linestest.tel.apply(lambda x: re.sub(\"'\", '', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation)\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.tel=lines.tel.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "linestest.eng=linestest.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "linestest.tel=linestest.tel.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"[0123456789]\", \"\", x))\n",
    "lines.tel = lines.tel.apply(lambda x: re.sub(\"[0123456789]\", \"\", x))\n",
    "linestest.eng=linestest.eng.apply(lambda x: re.sub(\"[0123456789]\", \"\", x))\n",
    "linestest.tel = linestest.tel.apply(lambda x: re.sub(\"[0123456789]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
    "lines.tel=lines.tel.apply(lambda x: x.strip())\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.tel=lines.tel.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.tel = lines.tel.apply(lambda x : 'S'+ x + 'E')\n",
    "linestest.eng=linestest.eng.apply(lambda x: x.strip())\n",
    "linestest.tel=linestest.tel.apply(lambda x: x.strip())\n",
    "linestest.eng=linestest.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "linestest.tel=linestest.tel.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "\n",
    "linestest.tel = linestest.tel.apply(lambda x : 'S'+ x + 'E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eng_words=set()\n",
    "for eng in lines.eng:\n",
    "    for word in eng:\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "for eng in linestest.eng:\n",
    "    for word in eng:\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Telugu_words=set()\n",
    "for tel in lines.tel:\n",
    "    for word in tel:\n",
    "        if word not in all_Telugu_words:\n",
    "            all_Telugu_words.add(word)\n",
    "for tel in linestest.tel:\n",
    "    for word in tel:\n",
    "        if word not in all_Telugu_words:\n",
    "            all_Telugu_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "lenght_list=[]\n",
    "for l in lines.eng:\n",
    "    lenght_list.append(len(l))\n",
    "for l in linestest.eng:\n",
    "    lenght_list.append(len(l))\n",
    "max_length_src = np.max(lenght_list)\n",
    "print(max_length_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "lenght_list=[]\n",
    "for l in lines.tel:\n",
    "    lenght_list.append(len(l))\n",
    "for l in linestest.tel:\n",
    "    lenght_list.append(len(l))\n",
    "max_length_tar = np.max(lenght_list)\n",
    "\n",
    "print(max_length_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 64\n"
     ]
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_Telugu_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_Telugu_words)\n",
    "print(num_encoder_tokens, num_decoder_tokens)\n",
    "num_decoder_tokens += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                eng            tel\n",
      "2238           విజయ         SవిజయE\n",
      "1327          నన్నీ        Sనన్నుE\n",
      "238       ఆనందించిన     SఆనందించుE\n",
      "2157          వచ్చి        Sవచ్చుE\n",
      "205          అసలుకి         SఅసలుE\n",
      "1597         పెద్దల        Sపెద్దE\n",
      "955        చెయ్యాలో       Sచెయ్యిE\n",
      "783        గడిచింది        SగడుచుE\n",
      "889   చిత్తశుద్ధితో  Sచిత్తశుద్ధిE\n",
      "821       గుర్తించే    Sగుర్తించుE\n"
     ]
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "print(lines.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'అంత'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = lines.eng, lines.tel\n",
    "X_test,y_test=linestest.eng,linestest.tel\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.001)\n",
    "y_train.shape,y_test.shape,y_val.shape\n",
    "X_test[3:4].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle('Weights_Tel/X_train.pkl')\n",
    "X_test.to_pickle('Weights_Tel/X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 10):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src+1),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar+1),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar+1, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text):\n",
    "                    if t<len(target_text)-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens+1, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2600, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_val)\n",
    "batch_size = 5\n",
    "epochs = 100\n",
    "\n",
    "train_samples,val_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = int(train_samples/batch_size),validation_steps = int(val_samples/1),\n",
    "                    epochs=epochs,\n",
    "                    shuffle=True,validation_data = generate_batch(X_val, y_val, batch_size = 1))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights_epoch100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('nmt_weights_epoch100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    #print(target_token_index)\n",
    "    target_seq[0, 0] = target_token_index['S']\n",
    "   \n",
    "\n",
    "    #print(target_seq)\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == 'E'  or len(decoded_sentence) > 100):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        #print(sampled_token_index)\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(NNinp):\n",
    "    X_test[0]=NNinp\n",
    "    test=[]\n",
    "    test+=[X_test[0]]\n",
    "    train_gen = generate_batch(test, [''], batch_size = 1)\n",
    "    (input_seq, actual_output), _ = next(train_gen)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    inp=X_test[0:1].values[0]\n",
    "    pred=decoded_sentence\n",
    "    return pred[:-1]\n",
    "    print('Input:', inp)\n",
    "    print('Lemma:', pred[:-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPOS(word):\n",
    "    mfinp=open(\"/home/anusha/Documents/sivareddyg-telugu-part-of-speech-tagger-9dbe2d21ca33/telugu.input.txt\",'w',encoding='utf-8')\n",
    "    mfop=open(\"/home/anusha/Documents/sivareddyg-telugu-part-of-speech-tagger-9dbe2d21ca33/telugu.output.txt\",'r',encoding='utf-8')\n",
    "    mfinp.write(word)\n",
    "    mfinp.close()\n",
    "    os.system('make tag -sC \\'/home/anusha/Documents/sivareddyg-telugu-part-of-speech-tagger-9dbe2d21ca33\\'')\n",
    "    x=mfop.readline()\n",
    "    a=x.split()\n",
    "    #print(a)\n",
    "    if  (('sg' in x) and (word[-2:]=='లు' or word[-1:]=='ల')):#(word[-3:]=='ులు' or word[-3:]=='ాలు' )) :\n",
    "        return(\"sg\")\n",
    "    elif (('RB' in x) and (word[-2:]=='గా')):\n",
    "        return(\"RB\")\n",
    "    elif(('sg' in x) and len(word)>4 and word[-4:]=='ాలలో'):\n",
    "\n",
    "            return(\"sg\")\n",
    "    elif( word[-3:]=='ికి'):\n",
    "        return(a[2].strip())\n",
    "    elif(word[-1:]=='ై'):\n",
    "        return(a[2].strip())\n",
    "\n",
    "    else:\n",
    "        return(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rules(inp,maxw,mx,total,hstem):\n",
    "\n",
    "    if(inp[-1]=='ం'):\n",
    "        if(len(inp)>5 and inp[-5:]=='కోవటం' or inp[-5:]=='కోవడం'):\n",
    "            maxw=inp[:-5]\n",
    "            maxw+='కొను'\n",
    "        elif(len(inp)>5 and inp[-5:]=='పోవడం' or inp[-5:]=='పోవటం'):\n",
    "            #total+=1\n",
    "            maxw=inp[:-5]\n",
    "            maxw+='పోవు'\n",
    "        elif(len(inp)>3 and inp[-3:]=='చడం' or inp[-3:]=='చటం'):\n",
    "            maxw=inp[:-2]\n",
    "            maxw+='ు'\n",
    "        elif(len(inp)>len('చ్చాం') and inp[-5:]=='చ్చాం' ):\n",
    "            maxw=inp[:-5]\n",
    "            maxw+='చ్చు'\n",
    "        else:\n",
    "            maxw=inp\n",
    "\n",
    "    elif(inp[-2:]=='లు'):\n",
    "        if(inp[-3:]=='ులు' ):\n",
    "            plural=findPOS(inp)\n",
    "\n",
    "            if(plural==\"not\"):\n",
    "                    maxw=inp[:-3]\n",
    "                    maxw+='ి'\n",
    "            else:\n",
    "                maxw=inp\n",
    "\n",
    "        elif(inp[-3:]=='ాలు'): #and mx!=1):\n",
    "            temp=inp\n",
    "            plural=findPOS(temp)\n",
    "            if(plural==\"not\"):\n",
    "                temp=temp[:-3]\n",
    "                temp+='ం'\n",
    "                maxw=temp\n",
    "            else:\n",
    "                maxw=temp\n",
    "        else:\n",
    "            plural=findPOS(inp)\n",
    "            if(plural==\"not\"):\n",
    "                if(len(inp)>len('ర్లు') and inp[-4:]=='ర్లు'):\n",
    "                    maxw=inp[:-4]\n",
    "                    maxw+='రు'\n",
    "                    #print('ర్లు',inp,maxw)\n",
    "                elif(len(inp)>len('న్లు') and inp[-4:]=='న్లు'):\n",
    "                    maxw=inp[:-4]\n",
    "                    maxw+='ను'\n",
    "                    #print('న్లు',inp,maxw)\n",
    "                elif(len(inp)>len('ట్లు') and inp[-4:]=='ట్లు'):\n",
    "                    maxw=inp[:-4]\n",
    "                    maxw+='ట్టు'\n",
    "                    #print('ట్లు',inp,maxw)\n",
    "                elif(len(inp)>len('ళ్లు') and inp[-4:]=='ళ్లు'):\n",
    "                    maxw=inp[:-4]\n",
    "                    maxw+='లు'\n",
    "                    #print('ళ్లు',inp,maxw)\n",
    "                elif(re.search('్లు$',inp)):\n",
    "                    maxw=inp[:-3]\n",
    "                    maxw+='ు'\n",
    "                    #print('ళ్లు',inp,maxw)\n",
    "                    \n",
    "\n",
    "                else:\n",
    "                    maxw=inp[:-2]\n",
    "            else:\n",
    "                maxw=inp\n",
    "    elif(inp[-2:]=='చి'):\n",
    "        maxw=inp[:-2]\n",
    "        if(len(inp)>len('ిచి') and inp[-3:]=='ిచి'):\n",
    "            maxw=inp[:-3]\n",
    "            maxw+='ుచు'\n",
    "        else:\n",
    "            maxw+='చు'\n",
    "    elif(len(inp)>=2 and inp[-2:]=='గా'):\n",
    "        if(len(inp)==2):\n",
    "            maxw=inp\n",
    "\n",
    "        elif(len(inp)>len('లుగా') and inp[-4:]=='లుగా'):\n",
    "            maxw,total=rules(inp[:-2],maxw,mx,total,hstem)\n",
    "\n",
    "        elif(len(inp)>4 and inp[-4:]=='లాగా'):\n",
    "            maxw=inp[:-4]\n",
    "        elif(len(inp)>4 and inp[-4:]=='గ్గా'):\n",
    "            maxw=inp[:-4]\n",
    "            maxw+='కు'\n",
    "        else:\n",
    "            maxw=inp[:-2]\n",
    "    elif(len(inp)>=2 and inp[-2:]=='లో'):\n",
    "        if(inp==2):\n",
    "            maxw=inp\n",
    "\n",
    "        elif(len(inp)>len('ల్లో') and inp[-4:]=='ల్లో'):\n",
    "\n",
    "            if(len(inp)>len('ళ్లల్లో') and inp[-7:]=='ళ్లల్లో' ):\n",
    "                maxw=inp[:-4]\n",
    "                maxw+='ు'\n",
    "            elif(len(inp)>len('ళ్ళల్లో') and inp[-7:]=='ళ్ళల్లో' ):\n",
    "                maxw=inp[:-4]\n",
    "                maxw+='ు'\n",
    "            elif(len(inp)>len('్లల్లో') and inp[-6:]=='్లల్లో'):\n",
    "                maxw=inp[:-4]\n",
    "                plural=findPOS(maxw)\n",
    "                if(plural==\"not\"):\n",
    "                    maxw,total=rules(maxw+'ు',maxw,mx,total,hstem)\n",
    "                \n",
    "            else:\n",
    "                temp=inp[:-4]+\"లు\"\n",
    "                maxw,total=rules(temp,maxw,mx,total,hstem)\n",
    "        elif(len(inp)>len('లలో') and inp[-3:]=='లలో'):\n",
    "            maxw=inp[:-2]\n",
    "            plural=findPOS(maxw)\n",
    "            if(plural==\"not\"):\n",
    "                maxw,total=rules(maxw+'ు',maxw,mx,total,hstem)\n",
    "        else:\n",
    "            maxw=inp[:-2]\n",
    "    elif(len(inp)>4 and inp[-4:]=='ల్ని'):\n",
    "        if(len(inp)==4):\n",
    "            maxw=inp\n",
    "        elif(inp[-5:]=='ాల్ని'):\n",
    "            maxw=inp[:-5]\n",
    "            maxw+='ం'\n",
    "        elif(inp[-5:]=='ుల్ని'):\n",
    "            maxw=inp[:-5]\n",
    "            maxw+='ి'\n",
    "        else:\n",
    "            maxw=inp[:-4]\n",
    "    elif(inp[-2:]=='చే' or inp[-2:]=='చె'):\n",
    "        if(len(inp)==2):\n",
    "            maxw=inp\n",
    "        elif(inp[-3:]=='ిచే' or inp[-3:]=='ిచె'):\n",
    "            maxw=inp[:-3]\n",
    "            maxw+='ుచు'\n",
    "        else:\n",
    "            maxw=inp[:-1]\n",
    "            maxw+='ు'\n",
    "    elif(inp[-2:]=='ను'):\n",
    "        if(len(inp)==2):\n",
    "            maxw=inp\n",
    "        elif(len(inp)>6 and inp[-6:]=='స్తాను'):\n",
    "            maxw=inp[:-6]\n",
    "            maxw+='ంచు'\n",
    "        elif(len(inp)>4 and inp[-4:]=='తాను'):\n",
    "            if(inp[-5]=='డ'):\n",
    "                maxw=inp[:-5]\n",
    "                maxw+='ట్టు'\n",
    "            else:\n",
    "                maxw=inp[:-4]\n",
    "        elif(len(inp)>4 and inp[-4:]=='యాను'):\n",
    "            maxw=inp[:-4]\n",
    "            maxw+='వు'\n",
    "        elif(len(inp)>len('న్నాను') and inp[-6:]=='న్నాను'):\n",
    "            maxw=inp[:-5]\n",
    "            maxw+='ు'\n",
    "        elif(len(inp)>len('రిగాను') and re.search('.*ి.ాను$',inp)):\n",
    "            maxw=inp[:-3]\n",
    "            maxw+='ు'\n",
    "            maxw=list(maxw)\n",
    "            maxw[-3]='ు'\n",
    "            maxw=''.join(maxw)\n",
    "        elif(len(inp)>3 and inp[-3:]=='ాను'):\n",
    "            maxw=inp[:-3]\n",
    "            maxw+='ు'\n",
    "        elif(len(inp)>3 and inp[-3:]=='లను'):\n",
    "            temp=inp[:-2]\n",
    "            temp+='ు'\n",
    "            maxw,total=rules(temp,maxw,mx,total,hstem)\n",
    "        elif(len(inp)>len('న్ను') and inp[-4:]=='న్ను'):\n",
    "            maxw=inp\n",
    "        elif(len(inp)>4 and (inp[-4:]=='చేను' or inp[-4:]=='చెను')):\n",
    "             maxw=inp[:-2]\n",
    "             maxw,total=rules(maxw,maxw,mx,total,hstem)\n",
    "        else:\n",
    "            if(len(inp)>2):\n",
    "                maxw=inp[:-2]\n",
    "    elif(len(inp)>=2 and inp[-2:]=='డు'):\n",
    "        if(len(inp)==2):\n",
    "            maxw=inp\n",
    "        elif(len(inp)>=3 and inp[-3:]=='ాడు'):\n",
    "\n",
    "            if(len(inp)>len('డిగాడు') and re.search('.*ి.ాడు$',inp)):\n",
    "                maxw=inp[:-3]\n",
    "                maxw+='ు'\n",
    "                maxw=list(maxw)\n",
    "                maxw[-3]='ు'\n",
    "                maxw=''.join(maxw)\n",
    "            elif(len(inp)>len('న్నాడు') and inp[-6:]=='న్నాడు' ):\n",
    "                maxw=inp[:-5]\n",
    "                maxw+='ు'\n",
    "            elif(len(inp)>len('తాడు') and inp[-4:]=='తాడు'):\n",
    "                maxw=inp[:-4]\n",
    "            elif(len(inp)>len('యాడు') and inp[-4:]=='యాడు'):\n",
    "                maxw=inp[:-4]\n",
    "                maxw+='వు'\n",
    "            elif(len(inp)>len('శాడు') and (inp[-4:]=='శాడు') or inp[-4:]=='సాడు'):\n",
    "                maxw=inp[:-4]\n",
    "                maxw+='యు'\n",
    "            elif(len(inp)>len('డ్డాడు') and inp[-6:]=='డ్డాడు'):\n",
    "                maxw=inp[:-6]\n",
    "                maxw+='డు'\n",
    "            else:\n",
    "                maxw=inp[:-3]\n",
    "                maxw+='ు'\n",
    "        elif(len(inp)>len('ిలేడు') and re.search('.+ి.ేడు$',inp)):\n",
    "            maxw=inp[:-3]\n",
    "            maxw+='ు'\n",
    "            maxw=list(maxw)\n",
    "            maxw[-3]='ు'\n",
    "            maxw=''.join(maxw)\n",
    "        elif(len(inp)>len('ేడు') and inp[-3:]=='ేడు'):\n",
    "            maxw=inp[:-3]\n",
    "            maxw+='ు'\n",
    "        else:\n",
    "            maxw=inp\n",
    "    elif(len(inp)>=2 and inp[-2:]=='ని'):\n",
    "        if(len(inp)==2):\n",
    "            maxw=inp\n",
    "        elif(inp[-4:]=='కుని'):\n",
    "            maxw=inp[:-4]\n",
    "            maxw+='కొను'\n",
    "        elif(len(inp)>len('ాన్ని') and inp[-5:]=='ాన్ని'):\n",
    "            maxw=inp[:-5]\n",
    "            maxw+='ం'\n",
    "        elif(len(inp)>len('న్ని') and inp[-4:]=='న్ని'):\n",
    "            maxw=inp\n",
    "        elif(len(inp)>len('్ని') and inp[-3:]=='్ని'):\n",
    "            maxw=inp[:-3]\n",
    "            maxw+='ు'\n",
    "        elif(len(inp)>len('కొని') and inp[-4:]=='కొని'):\n",
    "            if(len(inp)>len('క్కొని') and inp[-6:]=='క్కొని'):\n",
    "                maxw=inp[:-6]\n",
    "                maxw+='గు'\n",
    "            else:\n",
    "                maxw=inp[:-4]\n",
    "        elif(len(inp)>len('లోని') and inp[-4:]=='లోని'):\n",
    "            maxw,total=rules(inp[:-2],maxw,mx,total,hstem)\n",
    "        elif(len(inp)>3 and inp[-3:]=='లని'):\n",
    "            maxw=inp[:-2]\n",
    "            maxw+='ు'\n",
    "            maxw,total=rules(maxw,maxw,mx,total,hstem)\n",
    "        else:\n",
    "            maxw=inp[:-2]\n",
    "    elif(len(inp)>=2 and inp[-2:]=='తో'):\n",
    "        if(len(inp)==2):\n",
    "            maxw=inp\n",
    "        if(len(inp)>4 and inp[-4:]=='ాలతో'):\n",
    "            temp=inp[:-2]\n",
    "            temp+='ు'\n",
    "            plural=findPOS(temp)\n",
    "            if(plural==\"not\"):\n",
    "                maxw=temp[:-3]\n",
    "                maxw+='ం'\n",
    "        elif(len(inp)>3 and inp[-3:]=='లతో'):\n",
    "            maxw=inp[:-2]\n",
    "            maxw=maxw+'ు'\n",
    "            plural=findPOS(maxw)\n",
    "            if(plural==\"not\"):\n",
    "                maxw,total=rules(maxw,maxw,mx,total,hstem)\n",
    "        elif(len(inp)>len('ల్తో') and inp[-4:]=='ల్తో'):\n",
    "            maxw=inp[:-3]\n",
    "            maxw+='ు'\n",
    "            plural=findPOS(maxw)\n",
    "            if(plural==\"not\"):\n",
    "                maxw,total=rules(maxw,maxw,mx,total,hstem)\n",
    "        elif(len(inp)>len('త్తో') and inp[-4:]=='త్తో'):\n",
    "            maxw=inp[:-3]\n",
    "            maxw+='ి'\n",
    "        else:\n",
    "            maxw=inp[:-2]\n",
    "    elif(inp[-1]=='ల'):\n",
    "\n",
    "        maxw=inp\n",
    "\n",
    "        plural=findPOS(maxw)\n",
    "        if(plural==\"not\"):\n",
    "            maxw,total=rules(maxw+'ు',maxw,mx,total,hstem)\n",
    "    elif(len(inp)>=2 and inp[-2:]=='కు'):\n",
    "        if(len(inp)==2):\n",
    "            maxw=inp\n",
    "        elif(len(inp)>3 and inp[-3:]=='లకు'):\n",
    "            plural=findPOS(inp[:-2])\n",
    "            if(plural=='not'):\n",
    "                temp=inp[:-2]\n",
    "                maxw,total=rules(temp+'ు',maxw,mx,total,hstem)\n",
    "            else:\n",
    "                maxw=inp[:-2]\n",
    "        elif(len(inp)>3 and inp[-3:]=='నకు'):\n",
    "            maxw=inp[:-3]\n",
    "        else:\n",
    "            maxw=inp[:-2]\n",
    "    elif(len(inp)>=3 and inp[-3:]=='ంది'):\n",
    "\n",
    "        if(len(inp)>len('ింది') and inp[-4:]=='ింది'):\n",
    "            if(len(inp)>len('ిగింది') and re.search('.+ి.ింది$',inp)):\n",
    "                maxw=inp[:-4]\n",
    "                maxw+='ు'\n",
    "                maxw=list(maxw)\n",
    "                maxw[-3]='ు'\n",
    "                maxw=''.join(maxw)\n",
    "            elif(len(inp)>len('ేసింది') and inp[-6:]=='ేసింది'):\n",
    "                maxw=inp[:-6]\n",
    "                maxw+='ు'\n",
    "            elif(len(inp)>len('యింది') and inp[-5:]=='యింది'):\n",
    "                maxw=inp[:-5]\n",
    "                maxw+='వు'\n",
    "            else:\n",
    "                maxw=inp[:-4]\n",
    "                maxw+='ు'\n",
    "        elif(len(inp)>len('స్తుంది') and inp[-7:]=='స్తుంది'):\n",
    "            maxw=inp[:-7]\n",
    "            maxw+='యు'\n",
    "        elif(len(inp)>len('తుంది') and inp[-5:]=='తుంది'):\n",
    "            maxw=inp[:-5]\n",
    "            maxw+='వు'\n",
    "        elif(len(inp)>len('కుంది') and inp[-5:]=='కుంది'):\n",
    "            maxw=inp[:-5]\n",
    "            maxw+='కొను'\n",
    "        elif(len(inp)>len('ొంది') and inp[-4:]=='ొంది'):\n",
    "            maxw=inp[:-3]\n",
    "            maxw+='ను'\n",
    "\n",
    "        else:\n",
    "            maxw=inp\n",
    "    elif(len(inp)>len('న') and inp[-1:]=='న' and inp[-3:]!='న్న' ):\n",
    "\n",
    "        if(len(inp)>len('ిలిన') and re.search('.+ి.ిన$',inp)):\n",
    "\n",
    "            maxw=inp[:-2]\n",
    "            maxw+='ు'\n",
    "            maxw=list(maxw)\n",
    "            maxw[-3]='ు'\n",
    "            maxw=''.join(maxw)\n",
    "        elif(len(inp)>len('ాల్సిన') and re.search('.+ాల్సిన$',inp)):\n",
    "            maxw=inp[:-6]\n",
    "            maxw+='ు'\n",
    "        elif(len(inp)>len('సిన') and inp[-3:]=='సిన'):\n",
    "\n",
    "            maxw=inp[:-3]\n",
    "            maxw+='యు'\n",
    "        elif(len(inp)>len('యిన') and inp[-3:]=='యిన'):\n",
    "\n",
    "            maxw=inp[:-3]\n",
    "            maxw+='వు'\n",
    "        elif(len(inp)>2 and inp[-2:]=='ిన'):\n",
    "\n",
    "            maxw=inp[:-2]\n",
    "            maxw+='ు'\n",
    "        elif(len(inp)>len('ైన') and inp[-2:]=='ైన'):\n",
    "            maxw=inp[:-2]\n",
    "            maxw+='ు'\n",
    "        elif(len(inp)>len('ున') and inp[-2:]=='ున'):\n",
    "            maxw=inp[:-1]\n",
    "        else:\n",
    "            maxw=inp\n",
    "    elif(len(inp)>2 and (inp[-2:]=='కి' or inp[-2:]==\"కీ\")):\n",
    "\n",
    "        if(len(inp)>3 and (inp[-3:]=='లకి'or inp[-3:]=='లకీ')):\n",
    "            maxw=inp[:-2]\n",
    "            plural=findPOS(maxw)\n",
    "            if(plural==\"not\"):\n",
    "                maxw,total=rules(maxw+'ు',maxw,mx,total,hstem)\n",
    "        elif(len(inp)>len('ానికి') and (inp[-5:]=='ానికి' or inp[-5:]=='ానికీ')):\n",
    "            maxw=inp[:-5]\n",
    "            maxw+='ం'\n",
    "            maxw,total=rules(maxw,maxw,mx,total,hstem)\n",
    "\n",
    "        elif(len(inp)>len('ికి') and (inp[-3:]=='ికి' or inp[-3:]=='ికీ')):\n",
    "            pos=findPOS(inp)\n",
    "            if(pos==\"NN\" or pos==\"NNP\"):\n",
    "                maxw=inp[:-2]\n",
    "            elif(pos==\"NST\"):\n",
    "                maxw=inp[:-3]\n",
    "            else:\n",
    "                maxw=inp[:-3]\n",
    "                maxw+='ు'\n",
    "        elif(len(inp)>len('లోకి') and (inp[-4:]=='లోకి' or inp[-4:]=='లోకీ')):\n",
    "            maxw=inp[:-2]\n",
    "            maxw,total=rules(maxw,maxw,mx,total,hstem)\n",
    "        else:\n",
    "            maxw=inp[:-2]\n",
    "    elif(len(inp)>4 and inp[-4:]=='స్తూ'):\n",
    "\n",
    "        if(inp[-5:]=='ుస్తూ'):\n",
    "            maxw=inp[:-4]\n",
    "            maxw+='పు'\n",
    "        elif(inp[-5:]=='ూస్తూ'):\n",
    "            maxw=inp[:-4]\n",
    "            maxw+='డు'\n",
    "        elif(inp[-5:]=='ిస్తూ'):\n",
    "            maxw=inp[:-4]\n",
    "            maxw+='ంచు'\n",
    "        else:\n",
    "            maxw=inp[:-4]\n",
    "            maxw+='యు'\n",
    "    elif(len(inp)>1 and inp[-1:]=='ై'):\n",
    "        if(len(inp)>2 and inp[-3:]=='లపై'):\n",
    "            maxw=inp[:-2]\n",
    "            maxw,total=rules(maxw+'ు',maxw,mx,total,hstem)\n",
    "        elif(len(inp)>=2 and inp[-2:]=='పై'):\n",
    "            if(len(inp)==2):\n",
    "                maxw=inp\n",
    "\n",
    "            else:\n",
    "                maxw=inp[:-2]\n",
    "        else:\n",
    "            pos=findPOS(inp)\n",
    "            if(pos!='QC'):\n",
    "                maxw=inp[:-1]\n",
    "                maxw+='ు'\n",
    "            else:\n",
    "                maxw=inp\n",
    "        if (not ((hstem[inp]==maxw) or ((hstem[inp][:-1]==maxw[:-2]) and (hstem[inp][-1]=='ం' and maxw[-2:]=='ము')) or ((hstem[inp][:-2]==maxw[:-1]) and (maxw[-1]=='ం' and hstem[inp][-2:]=='ము')))):\n",
    "                total+=1\n",
    "                \"\"\"print(total,inp,hstem[inp],maxw)\"\"\"\n",
    "    elif(inp[-1]=='ట' or inp[-1]=='త'):\n",
    "        maxw=inp\n",
    "    else:\n",
    "\n",
    "        maxw=NN(inp)\n",
    "        total=0\n",
    "    return maxw,total\n",
    "\n",
    "            \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :పాపాలు\n",
      "Lemma :పాపం\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inp='పాపాలు'\n",
    "print(\"input :\"+inp)\n",
    "maxw,_=rules(inp,'',1,1,{})\n",
    "print(\"Lemma :\"+maxw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
